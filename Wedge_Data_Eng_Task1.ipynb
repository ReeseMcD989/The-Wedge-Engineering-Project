{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1354880d",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 1: Cleaning the Wedge transaction data files and uploading them to GBQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7197954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line imports the os module, which provides functions for interacting with the operating system. \n",
    "# It allows you to perform operations such as file and directory manipulation.\n",
    "\n",
    "import os\n",
    "\n",
    "# This line imports the re module, which provides support for regular expressions. \n",
    "# Regular expressions are a powerful tool for pattern matching and manipulation of strings.\n",
    "\n",
    "import re\n",
    "\n",
    "# This line imports the datetime module, which provides classes for manipulating dates and times. \n",
    "# It allows you to work with dates, times, time intervals, and perform various operations on them.\n",
    "\n",
    "import datetime \n",
    "\n",
    "# This line imports the ZipFile class from the zipfile module. It allows you to create, read, write, and \n",
    "# extract files from ZIP archives.\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# This line imports the pandas library and assigns it the alias pd. pandas is a powerful data manipulation and \n",
    "# analysis library in Python. It provides data structures and functions for efficiently working with structured \n",
    "# data, such as tables or CSV files.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# This line imports the numpy library and assigns it the alias np. numpy is a fundamental package for scientific \n",
    "# computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection \n",
    "# of mathematical functions to operate on them.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This line imports the pandas_gbq module, which provides functionality for working with Google BigQuery from within \n",
    "# the pandas library. It allows you to read data from and write data to BigQuery tables.\n",
    "\n",
    "import pandas_gbq\n",
    "\n",
    "# This line imports the janitor library, which provides additional cleaning and data manipulation functions for \n",
    "# pandas DataFrames. It extends the functionality of pandas and allows for more streamlined data cleaning operations.\n",
    "\n",
    "import janitor\n",
    "\n",
    "# This line imports the shutil module, which provides high-level file and directory operations. It allows you to \n",
    "# perform operations such as copying, moving, and deleting files or directories.\n",
    "\n",
    "import shutil\n",
    "\n",
    "# This line imports the glob module, which provides a function for searching directories and retrieving file paths \n",
    "# that match specified patterns. It allows for flexible file path matching based on wildcards and patterns.\n",
    "\n",
    "import glob\n",
    "\n",
    "# This line imports the bigquery module from the google.cloud package. It provides functionality for interacting with \n",
    "# Google BigQuery, a fully-managed, serverless data warehouse.\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# This line imports the service_account module from the google.oauth2 package. It provides support for authenticating \n",
    "# and authorizing access to Google Cloud services using a service account key.\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# This line imports the warnings module and will be used to stop warnings from printing to output for all code chunks.\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b5858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring all warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee7233",
   "metadata": {},
   "source": [
    "#### This next section of cells is necessary to generate lists of delimiters and headers that correspond with the .csv file names for use later on in the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224028ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of zip files in this directory.\n",
    "\n",
    "zip_files = os.listdir(\"WedgeZipOfZips/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4c50b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transArchive_201001_201003.zip',\n",
       " 'transArchive_201004_201006.zip',\n",
       " 'transArchive_201007_201009.zip',\n",
       " 'transArchive_201010_201012.zip',\n",
       " 'transArchive_201101_201103.zip',\n",
       " 'transArchive_201104.zip',\n",
       " 'transArchive_201105.zip',\n",
       " 'transArchive_201106.zip',\n",
       " 'transArchive_201107_201109.zip',\n",
       " 'transArchive_201110_201112.zip',\n",
       " 'transArchive_201201_201203.zip',\n",
       " 'transArchive_201201_201203_inactive.zip',\n",
       " 'transArchive_201204_201206.zip',\n",
       " 'transArchive_201204_201206_inactive.zip',\n",
       " 'transArchive_201207_201209.zip',\n",
       " 'transArchive_201207_201209_inactive.zip',\n",
       " 'transArchive_201210_201212.zip',\n",
       " 'transArchive_201210_201212_inactive.zip',\n",
       " 'transArchive_201301_201303.zip',\n",
       " 'transArchive_201301_201303_inactive.zip',\n",
       " 'transArchive_201304_201306.zip',\n",
       " 'transArchive_201304_201306_inactive.zip',\n",
       " 'transArchive_201307_201309.zip',\n",
       " 'transArchive_201307_201309_inactive.zip',\n",
       " 'transArchive_201310_201312.zip',\n",
       " 'transArchive_201310_201312_inactive.zip',\n",
       " 'transArchive_201401_201403.zip',\n",
       " 'transArchive_201401_201403_inactive.zip',\n",
       " 'transArchive_201404_201406.zip',\n",
       " 'transArchive_201404_201406_inactive.zip',\n",
       " 'transArchive_201407_201409.zip',\n",
       " 'transArchive_201407_201409_inactive.zip',\n",
       " 'transArchive_201410_201412.zip',\n",
       " 'transArchive_201410_201412_inactive.zip',\n",
       " 'transArchive_201501_201503.zip',\n",
       " 'transArchive_201504_201506.zip',\n",
       " 'transArchive_201507_201509.zip',\n",
       " 'transArchive_201510.zip',\n",
       " 'transArchive_201511.zip',\n",
       " 'transArchive_201512.zip',\n",
       " 'transArchive_201601.zip',\n",
       " 'transArchive_201602.zip',\n",
       " 'transArchive_201603.zip',\n",
       " 'transArchive_201604.zip',\n",
       " 'transArchive_201605.zip',\n",
       " 'transArchive_201606.zip',\n",
       " 'transArchive_201607.zip',\n",
       " 'transArchive_201608.zip',\n",
       " 'transArchive_201609.zip',\n",
       " 'transArchive_201610.zip',\n",
       " 'transArchive_201611.zip',\n",
       " 'transArchive_201612.zip',\n",
       " 'transArchive_201701.zip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the list of zip files\n",
    "\n",
    "zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeef05a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201001_201003.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201001_201003.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201001_201003.csv has delimiter , .\n",
      "\n",
      "['transArchive_201004_201006.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201004_201006.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201004_201006.csv has delimiter , .\n",
      "\n",
      "['transArchive_201007_201009.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201007_201009.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201007_201009.csv has delimiter , .\n",
      "\n",
      "['transArchive_201010_201012.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201010_201012.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201010_201012.csv has delimiter , .\n",
      "\n",
      "['transArchive_201101_201103.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201101_201103.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201101_201103.csv has delimiter , .\n",
      "\n",
      "['transArchive_201104.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201104.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201104.csv has delimiter , .\n",
      "\n",
      "['transArchive_201105.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201105.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201105.csv has delimiter , .\n",
      "\n",
      "['transArchive_201106.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201106.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201106.csv has delimiter , .\n",
      "\n",
      "['transArchive_201107_201109.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201107_201109.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201107_201109.csv has delimiter , .\n",
      "\n",
      "['transArchive_201110_201112.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201110_201112.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201110_201112.csv has delimiter , .\n",
      "\n",
      "['transArchive_201201_201203.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201201_201203.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201201_201203.csv has delimiter , .\n",
      "\n",
      "['transArchive_201201_201203_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201201_201203_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201201_201203_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201204_201206.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201204_201206.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201204_201206.csv has delimiter , .\n",
      "\n",
      "['transArchive_201204_201206_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201204_201206_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201204_201206_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201207_201209.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201207_201209.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201207_201209.csv has delimiter , .\n",
      "\n",
      "['transArchive_201207_201209_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201207_201209_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201207_201209_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201210_201212.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201210_201212.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201210_201212.csv has delimiter , .\n",
      "\n",
      "['transArchive_201210_201212_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201210_201212_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201210_201212_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201301_201303.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201301_201303.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201301_201303.csv has delimiter , .\n",
      "\n",
      "['transArchive_201301_201303_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201301_201303_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201301_201303_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201304_201306.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201304_201306.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201304_201306.csv has delimiter , .\n",
      "\n",
      "['transArchive_201304_201306_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201304_201306_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201304_201306_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201307_201309.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201307_201309.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201307_201309.csv has delimiter , .\n",
      "\n",
      "['transArchive_201307_201309_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201307_201309_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201307_201309_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201310_201312.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201310_201312.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201310_201312.csv has delimiter , .\n",
      "\n",
      "['transArchive_201310_201312_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201310_201312_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201310_201312_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201401_201403.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201401_201403.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201401_201403.csv has delimiter , .\n",
      "\n",
      "['transArchive_201401_201403_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201401_201403_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201401_201403_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201404_201406.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201404_201406.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201404_201406.csv has delimiter , .\n",
      "\n",
      "['transArchive_201404_201406_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201404_201406_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201404_201406_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201407_201409.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201407_201409.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201407_201409.csv has delimiter , .\n",
      "\n",
      "['transArchive_201407_201409_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201407_201409_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201407_201409_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201410_201412.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201410_201412.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201410_201412.csv has delimiter , .\n",
      "\n",
      "['transArchive_201410_201412_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201410_201412_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "It looks like transArchive_201410_201412_inactive.csv has delimiter ; .\n",
      "\n",
      "['transArchive_201501_201503.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201501_201503.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201501_201503.csv has delimiter , .\n",
      "\n",
      "['transArchive_201504_201506.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201504_201506.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201504_201506.csv has delimiter , .\n",
      "\n",
      "['transArchive_201507_201509.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201507_201509.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201507_201509.csv has delimiter , .\n",
      "\n",
      "['transArchive_201510.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201510.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201510.csv has delimiter , .\n",
      "\n",
      "['transArchive_201511.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201511.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201511.csv has delimiter , .\n",
      "\n",
      "['transArchive_201512.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201512.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201512.csv has delimiter , .\n",
      "\n",
      "['transArchive_201601.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201601.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201601.csv has delimiter , .\n",
      "\n",
      "['transArchive_201602.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201602.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201602.csv has delimiter , .\n",
      "\n",
      "['transArchive_201603.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201603.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201603.csv has delimiter , .\n",
      "\n",
      "['transArchive_201604.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201604.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201604.csv has delimiter , .\n",
      "\n",
      "['transArchive_201605.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201605.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201605.csv has delimiter , .\n",
      "\n",
      "['transArchive_201606.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201606.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201606.csv has delimiter , .\n",
      "\n",
      "['transArchive_201607.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201607.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201607.csv has delimiter , .\n",
      "\n",
      "['transArchive_201608.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201608.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201608.csv has delimiter , .\n",
      "\n",
      "['transArchive_201609.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201609.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201609.csv has delimiter , .\n",
      "\n",
      "['transArchive_201610.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201610.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201610.csv has delimiter , .\n",
      "\n",
      "['transArchive_201611.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201611.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201611.csv has delimiter , .\n",
      "\n",
      "['transArchive_201612.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201612.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201612.csv has delimiter , .\n",
      "\n",
      "['transArchive_201701.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201701.csv' encoding='utf-8'>\n",
      ",\n",
      "It looks like transArchive_201701.csv has delimiter , .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking to see what delimiters were used for each .csv file\n",
    "\n",
    "import csv # module for handling csv files\n",
    "import io # module for handling input/output operations\n",
    "\n",
    "# Here, a dictionary called delimiters is initialized. \n",
    "# This dictionary will store the filenames as keys and their corresponding delimiters as values.\n",
    "\n",
    "delimiters = dict() \n",
    "\n",
    "# Iterating over the list of filenames in the directory\n",
    "\n",
    "for this_zf in zip_files :\n",
    "    \n",
    "    # Within the loop, the code opens a ZIP file specified by \n",
    "    # \"WedgeZipOfZips/\" + this_zf in read mode ('r'). It assigns the opened ZIP file object to the variable zf. \n",
    "    # The with statement ensures that the ZIP file is properly closed after the code block is executed.\n",
    "    \n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf,'r') as zf : # r-read,w-write,a-append\n",
    "        \n",
    "        # This line retrieves a list of filenames contained within the currently opened ZIP file (zf) using the \n",
    "        # namelist() method. The list of filenames is assigned to the variable zipped_files.\n",
    "        \n",
    "        zipped_files = zf.namelist()\n",
    "        \n",
    "        # Another for loop is initiated within the previous loop, iterating over each file_name in the zipped_files list.\n",
    "        \n",
    "        for file_name in zipped_files :\n",
    "            \n",
    "            # Here, the code opens the current file_name within the ZIP file (zf) in read mode ('r'). \n",
    "            # The opened file object is assigned to the variable input_file.\n",
    "            \n",
    "            input_file = zf.open(file_name,'r')\n",
    "            \n",
    "            # This line wraps the input_file object with a TextIOWrapper from the io module, which allows \n",
    "            # reading the file in a text mode. It specifies the encoding as UTF-8.\n",
    "            \n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            # Here, the code uses the csv.Sniffer() class to automatically determine the delimiter used in the CSV file. \n",
    "            # It does this by reading a single line (sample) from the input_file and analyzing the characters that \n",
    "            # separate the values. The potential delimiters are specified as a list [\",\", \";\", \"\\t\"].\n",
    "            \n",
    "            dialect = csv.Sniffer().sniff(sample=input_file.readline(), delimiters=[\",\",\";\",\"\\t\"])\n",
    "            \n",
    "            # This line updates the delimiters dictionary. It sets the value for the current file_name as the delimiter \n",
    "            # detected in the dialect object.\n",
    "            \n",
    "            delimiters[file_name] = dialect.delimiter\n",
    "            \n",
    "            # These lines print a message indicating the detected delimiter for the current file. The join() method \n",
    "            # concatenates the strings within the provided list, separated by spaces, and the resulting message \n",
    "            # is printed to the console. \n",
    "            \n",
    "            print(zipped_files)\n",
    "            print(input_file)\n",
    "            print(dialect.delimiter)\n",
    "            print(\" \".join([\"It looks like\", file_name, \"has delimiter\", dialect.delimiter, \".\"]))\n",
    "            print()\n",
    "            \n",
    "            # This line closes the input_file object to free up system resources.\n",
    "            \n",
    "            input_file.close() # Tidy up.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde42555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transArchive_201001_201003.csv': ',',\n",
       " 'transArchive_201004_201006.csv': ',',\n",
       " 'transArchive_201007_201009.csv': ',',\n",
       " 'transArchive_201010_201012.csv': ',',\n",
       " 'transArchive_201101_201103.csv': ',',\n",
       " 'transArchive_201104.csv': ',',\n",
       " 'transArchive_201105.csv': ',',\n",
       " 'transArchive_201106.csv': ',',\n",
       " 'transArchive_201107_201109.csv': ',',\n",
       " 'transArchive_201110_201112.csv': ',',\n",
       " 'transArchive_201201_201203.csv': ',',\n",
       " 'transArchive_201201_201203_inactive.csv': ';',\n",
       " 'transArchive_201204_201206.csv': ',',\n",
       " 'transArchive_201204_201206_inactive.csv': ';',\n",
       " 'transArchive_201207_201209.csv': ',',\n",
       " 'transArchive_201207_201209_inactive.csv': ';',\n",
       " 'transArchive_201210_201212.csv': ',',\n",
       " 'transArchive_201210_201212_inactive.csv': ';',\n",
       " 'transArchive_201301_201303.csv': ',',\n",
       " 'transArchive_201301_201303_inactive.csv': ';',\n",
       " 'transArchive_201304_201306.csv': ',',\n",
       " 'transArchive_201304_201306_inactive.csv': ';',\n",
       " 'transArchive_201307_201309.csv': ',',\n",
       " 'transArchive_201307_201309_inactive.csv': ';',\n",
       " 'transArchive_201310_201312.csv': ',',\n",
       " 'transArchive_201310_201312_inactive.csv': ';',\n",
       " 'transArchive_201401_201403.csv': ',',\n",
       " 'transArchive_201401_201403_inactive.csv': ';',\n",
       " 'transArchive_201404_201406.csv': ',',\n",
       " 'transArchive_201404_201406_inactive.csv': ';',\n",
       " 'transArchive_201407_201409.csv': ',',\n",
       " 'transArchive_201407_201409_inactive.csv': ';',\n",
       " 'transArchive_201410_201412.csv': ',',\n",
       " 'transArchive_201410_201412_inactive.csv': ';',\n",
       " 'transArchive_201501_201503.csv': ',',\n",
       " 'transArchive_201504_201506.csv': ',',\n",
       " 'transArchive_201507_201509.csv': ',',\n",
       " 'transArchive_201510.csv': ',',\n",
       " 'transArchive_201511.csv': ',',\n",
       " 'transArchive_201512.csv': ',',\n",
       " 'transArchive_201601.csv': ',',\n",
       " 'transArchive_201602.csv': ',',\n",
       " 'transArchive_201603.csv': ',',\n",
       " 'transArchive_201604.csv': ',',\n",
       " 'transArchive_201605.csv': ',',\n",
       " 'transArchive_201606.csv': ',',\n",
       " 'transArchive_201607.csv': ',',\n",
       " 'transArchive_201608.csv': ',',\n",
       " 'transArchive_201609.csv': ',',\n",
       " 'transArchive_201610.csv': ',',\n",
       " 'transArchive_201611.csv': ',',\n",
       " 'transArchive_201612.csv': ',',\n",
       " 'transArchive_201701.csv': ','}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc415b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201001_201003.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201001_201003.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201001_201003.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201004_201006.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201004_201006.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201004_201006.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201007_201009.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201007_201009.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201007_201009.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201010_201012.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201010_201012.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201010_201012.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201101_201103.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201101_201103.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201101_201103.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201104.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201104.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201104.csv' encoding='utf-8'>\n",
      "['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id']\n",
      "\n",
      "['transArchive_201105.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201105.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201105.csv' encoding='utf-8'>\n",
      "['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id']\n",
      "\n",
      "['transArchive_201106.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201106.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201106.csv' encoding='utf-8'>\n",
      "['datetime', 'register_no', 'emp_no', 'trans_no', 'upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice', 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype', 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'memType', 'staff', 'numflag', 'itemstatus', 'tenderstatus', 'charflag', 'varflag', 'batchHeaderID', 'local', 'organic', 'display', 'receipt', 'card_no', 'store', 'branch', 'match_id', 'trans_id']\n",
      "\n",
      "['transArchive_201107_201109.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201107_201109.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201107_201109.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201110_201112.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201110_201112.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201110_201112.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201201_201203.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201201_201203.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201201_201203.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201201_201203_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201201_201203_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201201_201203_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201204_201206.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201204_201206.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201204_201206.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201204_201206_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201204_201206_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201204_201206_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201207_201209.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201207_201209.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201207_201209.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201207_201209_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201207_201209_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201207_201209_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201210_201212.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201210_201212.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201210_201212.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201210_201212_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201210_201212_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201210_201212_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201301_201303.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201301_201303.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201301_201303.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201301_201303_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201301_201303_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201301_201303_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201304_201306.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201304_201306.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201304_201306.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201304_201306_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201304_201306_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201304_201306_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201307_201309.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201307_201309.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201307_201309.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201307_201309_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201307_201309_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201307_201309_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201310_201312.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201310_201312.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201310_201312.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201310_201312_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201310_201312_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201310_201312_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201401_201403.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201401_201403.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201401_201403.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201401_201403_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201401_201403_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201401_201403_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201404_201406.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201404_201406.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201404_201406.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201404_201406_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201404_201406_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201404_201406_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201407_201409.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201407_201409.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201407_201409.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201407_201409_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201407_201409_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201407_201409_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201410_201412.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201410_201412.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201410_201412.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201410_201412_inactive.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201410_201412_inactive.csv' encoding='utf-8'>\n",
      ";\n",
      "<_io.TextIOWrapper name='transArchive_201410_201412_inactive.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201501_201503.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201501_201503.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201501_201503.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201504_201506.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201504_201506.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201504_201506.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201507_201509.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201507_201509.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201507_201509.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201510.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201510.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201510.csv' encoding='utf-8'>\n",
      "['\"datetime\"', '\"register_no\"', '\"emp_no\"', '\"trans_no\"', '\"upc\"', '\"description\"', '\"trans_type\"', '\"trans_subtype\"', '\"trans_status\"', '\"department\"', '\"quantity\"', '\"Scale\"', '\"cost\"', '\"unitPrice\"', '\"total\"', '\"regPrice\"', '\"altPrice\"', '\"tax\"', '\"taxexempt\"', '\"foodstamp\"', '\"wicable\"', '\"discount\"', '\"memDiscount\"', '\"discountable\"', '\"discounttype\"', '\"voided\"', '\"percentDiscount\"', '\"ItemQtty\"', '\"volDiscType\"', '\"volume\"', '\"VolSpecial\"', '\"mixMatch\"', '\"matched\"', '\"memType\"', '\"staff\"', '\"numflag\"', '\"itemstatus\"', '\"tenderstatus\"', '\"charflag\"', '\"varflag\"', '\"batchHeaderID\"', '\"local\"', '\"organic\"', '\"display\"', '\"receipt\"', '\"card_no\"', '\"store\"', '\"branch\"', '\"match_id\"', '\"trans_id\"']\n",
      "\n",
      "['transArchive_201511.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201511.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201511.csv' encoding='utf-8'>\n",
      "['2015-11-01 07:21:50', '51', '94', '4', 'TAX', 'Tax', 'A', '', '', '0', '0', '0', '0.0000', '0.0000', '0.4800', '0.0000', '\\\\N', '0', '0', '0', '\\\\N', '0.0000', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '52595', '1', '3', '0', '12']\n",
      "\n",
      "['transArchive_201512.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201512.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201512.csv' encoding='utf-8'>\n",
      "['2015-12-01 07:03:06', '51', '94', '2', 'TAX', 'Tax', 'A', '', '', '0', '0', '0', '0.0000', '0.0000', '0.0000', '0.0000', '', '0', '0', '0', '', '0.0000', '0.0000', '0', '0', '0', '', '0', '0', '0', '0.0000', '0', '0', '0', '', '0', '0', '0', '', '', '', '0', '', '', '0', '3', '1', '3', '0', '7']\n",
      "\n",
      "['transArchive_201601.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201601.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201601.csv' encoding='utf-8'>\n",
      "['2016-01-01 09:12:14', '51', '94', '3', '0000000000039', 'Wedge Scone', 'I', ' ', ' ', '8', '3', '0', '0.5160', '2.4900', '7.4700', '2.4900', '\\\\N', '0', '0', '1', '\\\\N', '0.0000', '0.0000', '1', '0', '0', '\\\\N', '3', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '5', '0', '0', '', '\\\\N', '\\\\N', '0', '0', '', '0', '3', '1', '3', '0', '10']\n",
      "\n",
      "['transArchive_201602.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201602.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201602.csv' encoding='utf-8'>\n",
      "['2016-02-01 07:16:56', '51', '94', '3', 'TAX', 'Tax', 'A', '', '', '0', '0', '0', '0.0000', '0.0000', '0.2700', '0.0000', '\\\\N', '0', '0', '0', '\\\\N', '0.0000', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '3', '1', '3', '0', '10']\n",
      "\n",
      "['transArchive_201603.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201603.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201603.csv' encoding='utf-8'>\n",
      "['2016-03-01 07:04:38', '51', '94', '2', 'TAX', 'Tax', 'A', '', '', '0', '0', '0', '0.0000', '0.0000', '0.0000', '0.0000', '\\\\N', '0', '0', '0', '\\\\N', '0.0000', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '3', '1', '3', '0', '10']\n",
      "\n",
      "['transArchive_201604.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201604.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201604.csv' encoding='utf-8'>\n",
      "['2016-04-01 07:34:35', '51', '94', '18', '0', 'Cash', 'T', 'CA', '', '0', '0', '0', '0.0000', '0.0000', '-5.0000', '0.0000', '\\\\N', '0', '0', '0', '\\\\N', '0.0000', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '49019', '1', '3', '0', '9']\n",
      "\n",
      "['transArchive_201605.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201605.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201605.csv' encoding='utf-8'>\n",
      "['2016-05-01 11:23:35', '51', '94', '113', '0000000004365', 'BBOWL SuperSoba Chicken/Seitan', 'I', ' ', ' ', '8', '1', '0', '0.0000', '10.0000', '10.0000', '10.0000', '\\\\N', '1', '0', '0', '0', '0.0000', '0.0000', '7', '0', '0', '0.00000000', '1', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '1', '0', '0', '', '\\\\N', '\\\\N', '0', '0', '', '0', '12539', '1', '3', '0', '4']\n",
      "\n",
      "['transArchive_201606.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201606.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201606.csv' encoding='utf-8'>\n",
      "['2016-06-01 08:04:44', '51', '94', '41', '0000000000151', 'Banana Organic', 'I', ' ', ' ', '2', '1.45', '1', '0.8900', '1.1900', '1.7300', '1.1900', '\\\\N', '0', '0', '1', '1', '0.0000', '0.0000', '1', '0', '0', '10.00000000', '1.45', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '1', '', '0', '12367', '1', '3', '0', '2']\n",
      "\n",
      "['transArchive_201607.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201607.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201607.csv' encoding='utf-8'>\n",
      "['2016-07-01 07:06:15', '51', '94', '1', '0065722700050', 'Electrolyte Water 1.5L Essenti', 'I', ' ', ' ', '1', '3', '0', '1.5800', '2.6900', '8.0700', '2.6900', '\\\\N', '0', '0', '1', '0', '0.0000', '0.0000', '1', '0', '0', '0.00000000', '3', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '0', '', '0', '3', '1', '3', '0', '1']\n",
      "\n",
      "['transArchive_201608.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201608.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201608.csv' encoding='utf-8'>\n",
      "['2016-08-01 07:34:16', '51', '94', '7', '0000000000151', 'Banana Organic', 'I', ' ', ' ', '2', '0.52', '1', '0.8900', '1.1900', '0.6200', '1.1900', '\\\\N', '0', '0', '1', '1', '0.0000', '0.0000', '1', '0', '0', '0.00000000', '0.52', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '1', '', '0', '21998', '1', '3', '0', '2']\n",
      "\n",
      "['transArchive_201609.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201609.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201609.csv' encoding='utf-8'>\n",
      "['2016-09-01 07:13:09', '51', '94', '6', '0', 'Change', 'T', 'CA', '', '0', '0', '0', '0.0000', '0.0000', '0.0000', '0.0000', '\\\\N', '0', '0', '0', '0', '0.0000', '0.0000', '0', '0', '8', '\\\\N', '0', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '20074', '1', '3', '0', '7']\n",
      "\n",
      "['transArchive_201610.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201610.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201610.csv' encoding='utf-8'>\n",
      "['2016-10-01 07:04:40', '51', '94', '1', 'DISCOUNT', 'Discount', 'I', '', '', '0', '1', '0', '0.0000', '0.0000', '0.0000', '0.0000', '\\\\N', '0', '0', '0', '0', '0.0000', '0.0000', '0', '0', '0', '\\\\N', '1', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '49355', '1', '3', '0', '10']\n",
      "\n",
      "['transArchive_201611.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201611.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201611.csv' encoding='utf-8'>\n",
      "['2016-11-01 07:18:44', '51', '94', '11', '0000000001014', 'Green Patch Redemption', 'I', ' ', ' ', '1', '1', '0', '0.0000', '-0.1000', '-0.1000', '-0.1000', '\\\\N', '0', '0', '0', '0', '0.0000', '0.0000', '0', '0', '0', '10.00000000', '1', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '4', '0', '0', '', '\\\\N', '\\\\N', '0', '-1', '', '0', '16646', '1', '3', '0', '13']\n",
      "\n",
      "['transArchive_201612.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201612.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201612.csv' encoding='utf-8'>\n",
      "['2016-12-01 07:43:01', '51', '94', '23', '0000000000049', 'Wedge Muffin', 'I', ' ', ' ', '8', '1', '0', '0.6350', '2.4900', '2.4900', '2.4900', '\\\\N', '0', '0', '1', '0', '0.0000', '0.0000', '7', '0', '0', '10.00000000', '1', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '5', '0', '0', '', '\\\\N', '\\\\N', '0', '0', '', '0', '13863', '1', '3', '0', '2']\n",
      "\n",
      "['transArchive_201701.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201701.csv' encoding='utf-8'>\n",
      ",\n",
      "<_io.TextIOWrapper name='transArchive_201701.csv' encoding='utf-8'>\n",
      "['2017-01-01 09:00:31', '51', '94', '12', '0', 'Change', 'T', 'CA', '', '0', '0', '0', '0.0000', '0.0000', '0.0000', '0.0000', '\\\\N', '0', '0', '0', '0', '0.0000', '0.0000', '0', '0', '8', '\\\\N', '0', '0', '0', '0.0000', '0', '0', '0', '\\\\N', '0', '0', '0', '', '\\\\N', '\\\\N', '0', '\\\\N', '', '0', '24528', '1', '3', '0', '12']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for headers\n",
    "\n",
    "# These lines initialize an empty dictionary called headers. This dictionary will store the filenames as keys and a \n",
    "# boolean value indicating whether the file has a header as values.\n",
    "\n",
    "headers = dict()\n",
    "\n",
    "# This line starts a for loop that iterates over each item (this_zf) in the zip_files list.\n",
    "\n",
    "for this_zf in zip_files :\n",
    "    \n",
    "    # Within the loop, the code opens a ZIP file specified by \"WedgeZipOfZips/\" + this_zf in read mode ('r'). \n",
    "    # It assigns the opened ZIP file object to the variable zf. The with statement ensures that the ZIP file \n",
    "    # is properly closed after the code block is executed.\n",
    "    \n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf,'r') as zf :\n",
    "        \n",
    "        # This line retrieves a list of filenames contained within the currently opened ZIP file (zf) using the \n",
    "        # namelist() method. The list of filenames is assigned to the variable zipped_files.\n",
    "        \n",
    "        zipped_files = zf.namelist()\n",
    "        \n",
    "        # Another for loop is initiated within the previous loop, iterating over each file_name in the zipped_files list.\n",
    "        \n",
    "        for file_name in zipped_files :\n",
    "            \n",
    "            # Here, the code opens the current file_name within the ZIP file (zf) in read mode ('r'). The opened \n",
    "            # file object is assigned to the variable input_file.\n",
    "            \n",
    "            input_file = zf.open(file_name,'r')\n",
    "            \n",
    "            # This line wraps the input_file object with a TextIOWrapper from the io module, which allows reading the \n",
    "            # file in a text mode. It specifies the encoding as UTF-8.\n",
    "            \n",
    "            input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "            # This line retrieves the delimiter associated with the current file_name from the delimiters dictionary \n",
    "            # and assigns it to the variable this_delimiter.\n",
    "            \n",
    "            this_delimiter = delimiters[file_name]\n",
    "            \n",
    "            # Just printing these so we know what file and such the first printed row is associated with\n",
    "            \n",
    "            print(zipped_files)\n",
    "            print(input_file)\n",
    "            print(this_delimiter)\n",
    "            \n",
    "            # Within this loop, the code iterates over each line in the input_file. However, it only processes the \n",
    "            # first line (break statement is used to exit the loop after the first iteration). The line itself is \n",
    "            # stripped of leading and trailing whitespace and then split into a list of values using the this_delimiter.\n",
    "            \n",
    "            for line in input_file :\n",
    "                print(input_file)\n",
    "                print(line.strip().split(this_delimiter))\n",
    "                print()\n",
    "                break     \n",
    "                \n",
    "            # This line assigns a boolean value to the headers dictionary for the current file_name. It checks if the \n",
    "            # string \"datetime\" is present in the last line read (line) and stores the result (True or False) as the \n",
    "            # value in the dictionary.\n",
    "            \n",
    "            headers[file_name] = \"datetime\" in line\n",
    "            \n",
    "            # This line closes the input_file object to free up system resources.       \n",
    "            \n",
    "            input_file.close() # Tidy up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe002c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201701.csv']\n",
      "<_io.TextIOWrapper name='transArchive_201701.csv' encoding='utf-8'>\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "# Just having a look.\n",
    "\n",
    "print(zipped_files)\n",
    "print(input_file)\n",
    "print(this_delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4111bb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transArchive_201001_201003.csv': True,\n",
       " 'transArchive_201004_201006.csv': True,\n",
       " 'transArchive_201007_201009.csv': True,\n",
       " 'transArchive_201010_201012.csv': True,\n",
       " 'transArchive_201101_201103.csv': True,\n",
       " 'transArchive_201104.csv': True,\n",
       " 'transArchive_201105.csv': True,\n",
       " 'transArchive_201106.csv': True,\n",
       " 'transArchive_201107_201109.csv': True,\n",
       " 'transArchive_201110_201112.csv': True,\n",
       " 'transArchive_201201_201203.csv': True,\n",
       " 'transArchive_201201_201203_inactive.csv': True,\n",
       " 'transArchive_201204_201206.csv': True,\n",
       " 'transArchive_201204_201206_inactive.csv': True,\n",
       " 'transArchive_201207_201209.csv': True,\n",
       " 'transArchive_201207_201209_inactive.csv': True,\n",
       " 'transArchive_201210_201212.csv': True,\n",
       " 'transArchive_201210_201212_inactive.csv': True,\n",
       " 'transArchive_201301_201303.csv': True,\n",
       " 'transArchive_201301_201303_inactive.csv': True,\n",
       " 'transArchive_201304_201306.csv': True,\n",
       " 'transArchive_201304_201306_inactive.csv': True,\n",
       " 'transArchive_201307_201309.csv': True,\n",
       " 'transArchive_201307_201309_inactive.csv': True,\n",
       " 'transArchive_201310_201312.csv': True,\n",
       " 'transArchive_201310_201312_inactive.csv': True,\n",
       " 'transArchive_201401_201403.csv': True,\n",
       " 'transArchive_201401_201403_inactive.csv': True,\n",
       " 'transArchive_201404_201406.csv': True,\n",
       " 'transArchive_201404_201406_inactive.csv': True,\n",
       " 'transArchive_201407_201409.csv': True,\n",
       " 'transArchive_201407_201409_inactive.csv': True,\n",
       " 'transArchive_201410_201412.csv': True,\n",
       " 'transArchive_201410_201412_inactive.csv': True,\n",
       " 'transArchive_201501_201503.csv': True,\n",
       " 'transArchive_201504_201506.csv': True,\n",
       " 'transArchive_201507_201509.csv': True,\n",
       " 'transArchive_201510.csv': True,\n",
       " 'transArchive_201511.csv': False,\n",
       " 'transArchive_201512.csv': False,\n",
       " 'transArchive_201601.csv': False,\n",
       " 'transArchive_201602.csv': False,\n",
       " 'transArchive_201603.csv': False,\n",
       " 'transArchive_201604.csv': False,\n",
       " 'transArchive_201605.csv': False,\n",
       " 'transArchive_201606.csv': False,\n",
       " 'transArchive_201607.csv': False,\n",
       " 'transArchive_201608.csv': False,\n",
       " 'transArchive_201609.csv': False,\n",
       " 'transArchive_201610.csv': False,\n",
       " 'transArchive_201611.csv': False,\n",
       " 'transArchive_201612.csv': False,\n",
       " 'transArchive_201701.csv': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just checking it out.\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef234cc",
   "metadata": {},
   "source": [
    "#### Next, the 'Wedge_Unzipped' directory is deleted if it exists. Then we need an extraction of the original zipped data into a new directory 'Wedge_Unzipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ce5b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot delete the folder as it doesn't exists\n"
     ]
    }
   ],
   "source": [
    "folderPath = 'Wedge_Unzipped';\n",
    "    \n",
    "# This line checks if the folder specified by folderPath exists or not. It uses the os.path.exists() function from \n",
    "# the os module to determine if the folder exists.\n",
    "\n",
    "if os.path.exists(folderPath):\n",
    "      \n",
    "    # If the folder exists, this line removes the folder and all its contents. It uses the shutil.rmtree() \n",
    "    # function from the shutil module to recursively delete the directory specified by folderPath.\n",
    "    \n",
    "    shutil.rmtree(folderPath)\n",
    "  \n",
    "    print(\"The folder has been deleted successfully!\")\n",
    "else:\n",
    "    print(\"Cannot delete the folder as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14936002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transArchive_201001_201003.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201004_201006.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201007_201009.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201010_201012.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201101_201103.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201104.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201105.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201106.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201107_201109.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201110_201112.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201201_201203.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201201_201203_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201204_201206.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201204_201206_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201207_201209.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201207_201209_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201210_201212.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201210_201212_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201301_201303.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201301_201303_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201304_201306.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201304_201306_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201307_201309.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201307_201309_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201310_201312.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201310_201312_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201401_201403.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201401_201403_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201404_201406.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201404_201406_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201407_201409.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201407_201409_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201410_201412.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201410_201412_inactive.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201501_201503.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201504_201506.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201507_201509.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201510.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201511.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201512.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201601.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201602.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201603.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201604.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201605.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201606.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201607.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201608.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201609.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201610.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201611.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201612.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n",
      "['transArchive_201701.csv']\n",
      "Extracting this file now...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracts all zips in 'WedgeZipOfZips' to 'Wedge_Unzipped'.\n",
    "\n",
    "# This line starts a for loop that iterates over each item (zipf) in the zip_files list.\n",
    "\n",
    "for zipf in zip_files :\n",
    "    \n",
    "    # Within the loop, the code opens a ZIP file specified by \"WedgeZipOfZips/\" + zipf in read mode ('r'). \n",
    "    # It assigns the opened ZIP file object to the variable zf. The with statement ensures that the ZIP file is \n",
    "    # properly closed after the code block is executed.\n",
    "    \n",
    "    with ZipFile(\"WedgeZipOfZips/\" + zipf,'r') as zf :  \n",
    "        print(zf.namelist())        \n",
    "        print('Extracting this file now...')\n",
    "        \n",
    "        # This line extracts all the files and directories from the currently opened ZIP file (zf) and saves them \n",
    "        # to the 'Wedge_Unzipped' directory. The extractall() method is used to perform the extraction.\n",
    "        \n",
    "        zf.extractall('Wedge_Unzipped')\n",
    "        print('Done!')\n",
    "        print()\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bf5d0",
   "metadata": {},
   "source": [
    "#### Now, the files in 'Wedge_Unzipped' that do not have headers need to be moved to a new directory called 'O_Headers' after deleting this directory if it exists. The code then converts the headerless csv files to files with headers and moves them back to 'Wedge_Unzipped'. After, we clean up 'O_Headers' as it is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c99062f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot delete the folder as it doesn't exists\n"
     ]
    }
   ],
   "source": [
    "folderPath = 'O_Headers';\n",
    "    \n",
    "# Check if folder exists or not.\n",
    "\n",
    "if os.path.exists(folderPath):\n",
    "      \n",
    "    # Delete Folder.\n",
    "    \n",
    "    shutil.rmtree(folderPath)\n",
    "  \n",
    "    print(\"The folder has been deleted successfully!\")\n",
    "else:\n",
    "    print(\"Cannot delete the folder as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af89b931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transArchive_201001_201003.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transArchive_201004_201006.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transArchive_201007_201009.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transArchive_201010_201012.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transArchive_201101_201103.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transArchive_201104.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transArchive_201105.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transArchive_201106.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>transArchive_201107_201109.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>transArchive_201110_201112.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>transArchive_201201_201203.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transArchive_201201_201203_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transArchive_201204_201206.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transArchive_201204_201206_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>transArchive_201207_201209.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>transArchive_201207_201209_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>transArchive_201210_201212.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>transArchive_201210_201212_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>transArchive_201301_201303.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>transArchive_201301_201303_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>transArchive_201304_201306.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>transArchive_201304_201306_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>transArchive_201307_201309.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transArchive_201307_201309_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>transArchive_201310_201312.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>transArchive_201310_201312_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transArchive_201401_201403.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>transArchive_201401_201403_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>transArchive_201404_201406.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transArchive_201404_201406_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>transArchive_201407_201409.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transArchive_201407_201409_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>transArchive_201410_201412.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>transArchive_201410_201412_inactive.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>transArchive_201501_201503.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>transArchive_201504_201506.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>transArchive_201507_201509.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>transArchive_201510.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>transArchive_201511.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>transArchive_201512.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>transArchive_201601.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>transArchive_201602.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>transArchive_201603.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>transArchive_201604.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>transArchive_201605.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>transArchive_201606.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>transArchive_201607.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transArchive_201608.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>transArchive_201609.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>transArchive_201610.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>transArchive_201611.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>transArchive_201612.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>transArchive_201701.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file  headers\n",
       "0            transArchive_201001_201003.csv     True\n",
       "1            transArchive_201004_201006.csv     True\n",
       "2            transArchive_201007_201009.csv     True\n",
       "3            transArchive_201010_201012.csv     True\n",
       "4            transArchive_201101_201103.csv     True\n",
       "5                   transArchive_201104.csv     True\n",
       "6                   transArchive_201105.csv     True\n",
       "7                   transArchive_201106.csv     True\n",
       "8            transArchive_201107_201109.csv     True\n",
       "9            transArchive_201110_201112.csv     True\n",
       "10           transArchive_201201_201203.csv     True\n",
       "11  transArchive_201201_201203_inactive.csv     True\n",
       "12           transArchive_201204_201206.csv     True\n",
       "13  transArchive_201204_201206_inactive.csv     True\n",
       "14           transArchive_201207_201209.csv     True\n",
       "15  transArchive_201207_201209_inactive.csv     True\n",
       "16           transArchive_201210_201212.csv     True\n",
       "17  transArchive_201210_201212_inactive.csv     True\n",
       "18           transArchive_201301_201303.csv     True\n",
       "19  transArchive_201301_201303_inactive.csv     True\n",
       "20           transArchive_201304_201306.csv     True\n",
       "21  transArchive_201304_201306_inactive.csv     True\n",
       "22           transArchive_201307_201309.csv     True\n",
       "23  transArchive_201307_201309_inactive.csv     True\n",
       "24           transArchive_201310_201312.csv     True\n",
       "25  transArchive_201310_201312_inactive.csv     True\n",
       "26           transArchive_201401_201403.csv     True\n",
       "27  transArchive_201401_201403_inactive.csv     True\n",
       "28           transArchive_201404_201406.csv     True\n",
       "29  transArchive_201404_201406_inactive.csv     True\n",
       "30           transArchive_201407_201409.csv     True\n",
       "31  transArchive_201407_201409_inactive.csv     True\n",
       "32           transArchive_201410_201412.csv     True\n",
       "33  transArchive_201410_201412_inactive.csv     True\n",
       "34           transArchive_201501_201503.csv     True\n",
       "35           transArchive_201504_201506.csv     True\n",
       "36           transArchive_201507_201509.csv     True\n",
       "37                  transArchive_201510.csv     True\n",
       "38                  transArchive_201511.csv    False\n",
       "39                  transArchive_201512.csv    False\n",
       "40                  transArchive_201601.csv    False\n",
       "41                  transArchive_201602.csv    False\n",
       "42                  transArchive_201603.csv    False\n",
       "43                  transArchive_201604.csv    False\n",
       "44                  transArchive_201605.csv    False\n",
       "45                  transArchive_201606.csv    False\n",
       "46                  transArchive_201607.csv    False\n",
       "47                  transArchive_201608.csv    False\n",
       "48                  transArchive_201609.csv    False\n",
       "49                  transArchive_201610.csv    False\n",
       "50                  transArchive_201611.csv    False\n",
       "51                  transArchive_201612.csv    False\n",
       "52                  transArchive_201701.csv    False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell converts the headers dictionary built earlier on into a dataframe.\n",
    "\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "# This for loop iterates over the values of the headers dictionary. It retrieves each value and appends it to the \n",
    "# values list.\n",
    "\n",
    "for value in headers.values():\n",
    "    values.append(value)\n",
    "    \n",
    "# This for loop iterates over the keys of the headers dictionary. It retrieves each key and appends it to the keys list. \n",
    "\n",
    "for key in headers.keys():\n",
    "    keys.append(key)\n",
    "\n",
    "# Column name list. \n",
    "\n",
    "col_names =  ['file', 'headers']\n",
    "  \n",
    "# Create an empty dataframe.\n",
    "# Add columns.\n",
    "\n",
    "headers_df  = pd.DataFrame(columns = col_names)\n",
    "headers_df.file = keys\n",
    "headers_df.headers = values\n",
    "\n",
    "# Show the dataframe.\n",
    "\n",
    "headers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95eec193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transArchive_201001_201003.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transArchive_201004_201006.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transArchive_201007_201009.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transArchive_201010_201012.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transArchive_201101_201103.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transArchive_201104.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transArchive_201105.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transArchive_201106.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>transArchive_201107_201109.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>transArchive_201110_201112.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>transArchive_201201_201203.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transArchive_201201_201203_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transArchive_201204_201206.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>transArchive_201204_201206_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>transArchive_201207_201209.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>transArchive_201207_201209_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>transArchive_201210_201212.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>transArchive_201210_201212_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>transArchive_201301_201303.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>transArchive_201301_201303_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>transArchive_201304_201306.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>transArchive_201304_201306_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>transArchive_201307_201309.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transArchive_201307_201309_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>transArchive_201310_201312.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>transArchive_201310_201312_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transArchive_201401_201403.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>transArchive_201401_201403_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>transArchive_201404_201406.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>transArchive_201404_201406_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>transArchive_201407_201409.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transArchive_201407_201409_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>transArchive_201410_201412.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>transArchive_201410_201412_inactive.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>transArchive_201501_201503.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>transArchive_201504_201506.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>transArchive_201507_201509.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>transArchive_201510.csv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>transArchive_201511.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>transArchive_201512.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>transArchive_201601.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>transArchive_201602.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>transArchive_201603.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>transArchive_201604.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>transArchive_201605.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>transArchive_201606.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>transArchive_201607.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transArchive_201608.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>transArchive_201609.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>transArchive_201610.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>transArchive_201611.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>transArchive_201612.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>transArchive_201701.csv</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file  headers\n",
       "0            transArchive_201001_201003.csv      1.0\n",
       "1            transArchive_201004_201006.csv      1.0\n",
       "2            transArchive_201007_201009.csv      1.0\n",
       "3            transArchive_201010_201012.csv      1.0\n",
       "4            transArchive_201101_201103.csv      1.0\n",
       "5                   transArchive_201104.csv      1.0\n",
       "6                   transArchive_201105.csv      1.0\n",
       "7                   transArchive_201106.csv      1.0\n",
       "8            transArchive_201107_201109.csv      1.0\n",
       "9            transArchive_201110_201112.csv      1.0\n",
       "10           transArchive_201201_201203.csv      1.0\n",
       "11  transArchive_201201_201203_inactive.csv      1.0\n",
       "12           transArchive_201204_201206.csv      1.0\n",
       "13  transArchive_201204_201206_inactive.csv      1.0\n",
       "14           transArchive_201207_201209.csv      1.0\n",
       "15  transArchive_201207_201209_inactive.csv      1.0\n",
       "16           transArchive_201210_201212.csv      1.0\n",
       "17  transArchive_201210_201212_inactive.csv      1.0\n",
       "18           transArchive_201301_201303.csv      1.0\n",
       "19  transArchive_201301_201303_inactive.csv      1.0\n",
       "20           transArchive_201304_201306.csv      1.0\n",
       "21  transArchive_201304_201306_inactive.csv      1.0\n",
       "22           transArchive_201307_201309.csv      1.0\n",
       "23  transArchive_201307_201309_inactive.csv      1.0\n",
       "24           transArchive_201310_201312.csv      1.0\n",
       "25  transArchive_201310_201312_inactive.csv      1.0\n",
       "26           transArchive_201401_201403.csv      1.0\n",
       "27  transArchive_201401_201403_inactive.csv      1.0\n",
       "28           transArchive_201404_201406.csv      1.0\n",
       "29  transArchive_201404_201406_inactive.csv      1.0\n",
       "30           transArchive_201407_201409.csv      1.0\n",
       "31  transArchive_201407_201409_inactive.csv      1.0\n",
       "32           transArchive_201410_201412.csv      1.0\n",
       "33  transArchive_201410_201412_inactive.csv      1.0\n",
       "34           transArchive_201501_201503.csv      1.0\n",
       "35           transArchive_201504_201506.csv      1.0\n",
       "36           transArchive_201507_201509.csv      1.0\n",
       "37                  transArchive_201510.csv      1.0\n",
       "38                  transArchive_201511.csv      0.0\n",
       "39                  transArchive_201512.csv      0.0\n",
       "40                  transArchive_201601.csv      0.0\n",
       "41                  transArchive_201602.csv      0.0\n",
       "42                  transArchive_201603.csv      0.0\n",
       "43                  transArchive_201604.csv      0.0\n",
       "44                  transArchive_201605.csv      0.0\n",
       "45                  transArchive_201606.csv      0.0\n",
       "46                  transArchive_201607.csv      0.0\n",
       "47                  transArchive_201608.csv      0.0\n",
       "48                  transArchive_201609.csv      0.0\n",
       "49                  transArchive_201610.csv      0.0\n",
       "50                  transArchive_201611.csv      0.0\n",
       "51                  transArchive_201612.csv      0.0\n",
       "52                  transArchive_201701.csv      0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts boolean to float.\n",
    "\n",
    "headers_df['headers'] = headers_df['headers'].astype(float)\n",
    "headers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "469d011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of files with no headers.\n",
    "\n",
    "# This line filters the headers_df dataframe to select rows where the value in the 'headers' column is equal to 0. \n",
    "# It creates a new dataframe called headless that contains only those rows.\n",
    "\n",
    "headless = headers_df[(headers_df.headers == 0)]\n",
    "\n",
    "# Pulling 'file' from headless and reassigning headless\n",
    "\n",
    "headless = headless.file\n",
    "\n",
    "# Creating empty list\n",
    "\n",
    "file_names_headless = []\n",
    "\n",
    "# taking all file names from list of files without headers and putting them in the empty list\n",
    "\n",
    "for file_name in headless :\n",
    "    file_names_headless.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03f0ac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "# Creates 'O_Headers' directory.\n",
    "\n",
    "# This line assigns the string \"O_Headers\" to the variable path. It represents the path of the directory that will \n",
    "# be created if it doesn't already exist.\n",
    "\n",
    "path = \"O_Headers\"\n",
    "\n",
    "# This line checks if the directory specified by path exists or not. It uses the os.path.exists() function from the \n",
    "# os module to determine if the directory exists. The result is stored in the variable isExist.\n",
    "\n",
    "isExist = os.path.exists(path)\n",
    "\n",
    "# This line starts an if statement that checks if the isExist variable is False, indicating that the directory does \n",
    "# not exist.\n",
    "\n",
    "if not isExist:\n",
    "    \n",
    "    # If the directory does not exist, this line creates the directory specified by path using the os.makedirs() \n",
    "    # function from the os module. It creates any necessary parent directories as well.\n",
    "    \n",
    "    os.makedirs(path)\n",
    "    print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2458a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: transArchive_201511.csv\n",
      "Moved: transArchive_201512.csv\n",
      "Moved: transArchive_201601.csv\n",
      "Moved: transArchive_201602.csv\n",
      "Moved: transArchive_201603.csv\n",
      "Moved: transArchive_201604.csv\n",
      "Moved: transArchive_201605.csv\n",
      "Moved: transArchive_201606.csv\n",
      "Moved: transArchive_201607.csv\n",
      "Moved: transArchive_201608.csv\n",
      "Moved: transArchive_201609.csv\n",
      "Moved: transArchive_201610.csv\n",
      "Moved: transArchive_201611.csv\n",
      "Moved: transArchive_201612.csv\n",
      "Moved: transArchive_201701.csv\n"
     ]
    }
   ],
   "source": [
    "# Moves files with no headers to 'O_Headers'.\n",
    "\n",
    "# These lines define the source folder, destination folder, and the list of files to move. source_folder represents \n",
    "# the path of the folder where the files are currently located. destination_folder represents the path of the \n",
    "# folder where the files will be moved to. files_to_move is a list of file names that need to be moved.\n",
    "\n",
    "source_folder = r\"Wedge_Unzipped\\\\\"\n",
    "destination_folder = r\"O_Headers\\\\\"\n",
    "files_to_move = file_names_headless\n",
    "\n",
    "# This line starts a for loop that iterates over each file name in the files_to_move list.\n",
    "\n",
    "for file in files_to_move:\n",
    "    \n",
    "    # These lines construct the full file paths for the source and destination of each file to be moved. They \n",
    "    # concatenate the source_folder and destination_folder paths with the current file name to create the full paths.\n",
    "    \n",
    "    source = source_folder + file\n",
    "    destination = destination_folder + file\n",
    "    \n",
    "    # This line moves the file from the source path to the destination path using the shutil.move() function from the \n",
    "    # shutil module. It effectively performs the file move operation.\n",
    "    \n",
    "    shutil.move(source, destination)\n",
    "    print('Moved:', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8229ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
      "C:\\Users\\rsmcd\\AppData\\Local\\Temp\\ipykernel_16908\\1505019201.py:9: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n"
     ]
    }
   ],
   "source": [
    "# This line uses the os.listdir() function to retrieve a list of file names in the directory specified as \"O_Headers\". \n",
    "# It assigns the list of file names to the variable headless_list.\n",
    "\n",
    "headless_list = os.listdir(\"O_Headers\")\n",
    "\n",
    "# This for loop iterates over each file name in the headless_list. It reads each CSV file located in the \"O_headers\" \n",
    "# directory using pd.read_csv() from the pandas library. It assigns the resulting DataFrame to the variable big_heads. \n",
    "# The header=None argument is used to indicate that the CSV file does not have a header row.\n",
    "\n",
    "for headless in headless_list :\n",
    "    big_heads = pd.read_csv('O_headers\\\\'+headless, header = None)\n",
    "    \n",
    "# This for loop iterates over each file name in the headless_list. \n",
    "\n",
    "for headless in headless_list :\n",
    "    \n",
    "    # It specifies the output path as 'Wedge_Unzipped\\\\'\n",
    "    \n",
    "    path = 'Wedge_Unzipped\\\\'\n",
    "    \n",
    "    # and uses the to_csv() method on the big_heads DataFrame to write the DataFrame to a CSV file with the same name as \n",
    "    # the original file. # The header argument is used to provide a list of column names for the output CSV file.\n",
    "    \n",
    "    big_heads.to_csv(\n",
    "        path + headless,\n",
    "        header=[\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\"trans_subtype\",\n",
    "                \"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\"regPrice\",\"altPrice\",\n",
    "                \"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\"discounttype\",\n",
    "                \"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\"matched\",\n",
    "                \"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\"local\",\n",
    "                \"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"],\n",
    "        index=False) # The index=False argument ensures that the index column is not included in the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b86555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder has been deleted successfully!\n"
     ]
    }
   ],
   "source": [
    "# This chunk deletes the now useless 'O_Headers' directory.\n",
    "\n",
    "# This line assigns the string 'O_Headers' to the variable folderPath. It represents the path of the directory that \n",
    "# will be deleted if it exists.\n",
    "\n",
    "folderPath = 'O_Headers';\n",
    "    \n",
    "# This line checks if the directory specified by folderPath exists or not. It uses the os.path.exists() function \n",
    "# from the os module to determine if the directory exists.\n",
    "\n",
    "if os.path.exists(folderPath):\n",
    "      \n",
    "    # If the directory exists, this line removes the directory and its contents using the shutil.rmtree() function \n",
    "    # from the shutil module. It effectively deletes the directory and all its subdirectories and files.\n",
    "    \n",
    "    shutil.rmtree(folderPath)\n",
    "  \n",
    "    print(\"The folder has been deleted successfully!\")\n",
    "else:\n",
    "    print(\"Cannot delete the folder as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb81be5",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now we need to upload the data to GBQ after establishing a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79551e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the private key.\n",
    "\n",
    "# This line assigns the string representing the path to the JSON file to the variable service_path. It specifies the \n",
    "# directory path where the JSON file is located.\n",
    "\n",
    "service_path = \"C:\\\\Users\\\\rsmcd\\\\OneDrive\\\\Desktop\\\\MSBA Fall 2022\\\\\" # Path to json file.\n",
    "\n",
    "# This line assigns the string representing the name of the JSON file to the variable service_file. It specifies the \n",
    "# name of the JSON file, including its extension.\n",
    "\n",
    "service_file = 'reese-msba-9558fdd20984.json' # Name of json file.\n",
    "\n",
    "# This line assigns the string representing the name of the Google BigQuery project to the variable gbq_proj_id. It \n",
    "# specifies the project ID associated with the Google BigQuery service.\n",
    "\n",
    "gbq_proj_id = 'reese-msba' # Name of project.\n",
    "\n",
    "# This line concatenates the service_path and service_file variables to form the complete file path to the JSON file. \n",
    "# It assigns this concatenated path string to the variable private_key. The private_key variable now holds the full \n",
    "# path to the JSON file, which can be used to authenticate and access the Google BigQuery service.\n",
    "\n",
    "private_key =service_path + service_file # Creates single variable that leads to json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b244db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reese-msba:dram_shop\n",
      "reese-msba:wedge_transactions\n"
     ]
    }
   ],
   "source": [
    "# A connection to Google BigQuery is established here using the credentials from a service account JSON file. The code then \n",
    "# lists the datasets available in the connected BigQuery project.\n",
    "\n",
    "# Now we pass in our credentials so that Python has permission to access our project. This line uses the \n",
    "# from_service_account_file() method from the service_account module to create credentials for authentication. It takes \n",
    "# the complete file path to the service account JSON file (service_path + service_file) and generates the credentials \n",
    "# object.\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And finally we establish our connection. This line creates a BigQuery client object using the Client() constructor \n",
    "# from the bigquery module. It passes the credentials object and the gbq_proj_id as parameters to authenticate the \n",
    "# client connection. This establishes the connection to the specified BigQuery project.\n",
    "\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)\n",
    "\n",
    "# Look at list of data sets in client. This code block uses a for loop to iterate over the datasets in the connected \n",
    "# BigQuery project. The client.list_datasets() method retrieves a list of all datasets, and each item represents a \n",
    "# dataset. The item.full_dataset_id attribute is printed, which contains the full identifier of the dataset, including \n",
    "# the project ID and dataset name.\n",
    "\n",
    "for item in client.list_datasets() : \n",
    "    print(item.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c8e2b",
   "metadata": {},
   "source": [
    "#### This body of code cleans up the files and uploads to GBQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24b31536",
   "metadata": {},
   "outputs": [
    {
     "ename": "GenericGBQException",
     "evalue": "Reason: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/reese-msba/datasets/wedge_transactions/tables?prettyPrint=false: Billing has not been enabled for this project. Enable billing at https://console.cloud.google.com/billing. Datasets must have a default expiration time and default partition expiration time of less than 60 days while in sandbox mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_gbq\\gbq.py:1329\u001b[0m, in \u001b[0;36m_Table.create\u001b[1;34m(self, table_id, schema)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_error \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:725\u001b[0m, in \u001b[0;36mClient.create_table\u001b[1;34m(self, table, exists_ok, retry, timeout)\u001b[0m\n\u001b[0;32m    724\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset_id}\n\u001b[1;32m--> 725\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.createTable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Table\u001b[38;5;241m.\u001b[39mfrom_api_repr(api_response)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:759\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    757\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    758\u001b[0m     ):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\api_core\\retry.py:283\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    282\u001b[0m )\n\u001b[1;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\api_core\\retry.py:190\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/reese-msba/datasets/wedge_transactions/tables?prettyPrint=false: Billing has not been enabled for this project. Enable billing at https://console.cloud.google.com/billing. Datasets must have a default expiration time and default partition expiration time of less than 60 days while in sandbox mode.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGenericGBQException\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([gbq_proj_id,dataset_id,table_name])\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This line uses the to_gbq() function from the pandas_gbq module to write the big_wedge DataFrame to the \u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# specified BigQuery table.\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[43mpandas_gbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_gbq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbig_wedge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgbq_proj_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_gbq\\gbq.py:1174\u001b[0m, in \u001b[0;36mto_gbq\u001b[1;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TableCreationError(\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not create the table because it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready exists. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChange the if_exists parameter to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1172\u001b[0m     )\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m if_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_and_recreate_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_id_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_schema\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pandas_gbq\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mschema_is_subset(original_schema, table_schema):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_gbq\\gbq.py:615\u001b[0m, in \u001b[0;36mGbqConnector.delete_and_recreate_table\u001b[1;34m(self, project_id, dataset_id, table_id, table_schema)\u001b[0m\n\u001b[0;32m    613\u001b[0m table \u001b[38;5;241m=\u001b[39m _Table(project_id, dataset_id, credentials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcredentials)\n\u001b[0;32m    614\u001b[0m table\u001b[38;5;241m.\u001b[39mdelete(table_id)\n\u001b[1;32m--> 615\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_gbq\\gbq.py:1331\u001b[0m, in \u001b[0;36m_Table.create\u001b[1;34m(self, table_id, schema)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate_table(table)\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_error \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m-> 1331\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas_gbq\\gbq.py:386\u001b[0m, in \u001b[0;36mGbqConnector.process_http_error\u001b[1;34m(ex)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mmessage:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QueryTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReason: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ex))\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m GenericGBQException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReason: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ex))\n",
      "\u001b[1;31mGenericGBQException\u001b[0m: Reason: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/reese-msba/datasets/wedge_transactions/tables?prettyPrint=false: Billing has not been enabled for this project. Enable billing at https://console.cloud.google.com/billing. Datasets must have a default expiration time and default partition expiration time of less than 60 days while in sandbox mode."
     ]
    }
   ],
   "source": [
    "# This line assigns the string 'reese-msba' to the variable gbq_proj_id. It represents the Google BigQuery project ID to \n",
    "# which you want to connect.\n",
    "\n",
    "gbq_proj_id = 'reese-msba'\n",
    "\n",
    "# This line assigns the string 'wedge_transactions' to the variable dataset_id. It represents the dataset ID within the \n",
    "# specified Google BigQuery project where you want to perform operations.\n",
    "\n",
    "dataset_id = 'wedge_transactions'\n",
    "\n",
    "# This line uses the os.listdir() function to retrieve a list of filenames within the directory \"Wedge_Unzipped\". It \n",
    "# assigns the list of filenames to the variable unzipped_files. The os.listdir() function returns a list of all files \n",
    "# and directories present in the specified directory.\n",
    "\n",
    "unzipped_files = os.listdir(\"Wedge_Unzipped\")\n",
    "\n",
    "# Iterating through the list of unzipped files that all should now have headers. The following are cleaning operations\n",
    "# that unify data types and correct inconsistencies in entry of booleans and nulls. After, the data is loaded into GBQ.\n",
    "\n",
    "for uz_file in unzipped_files :    \n",
    "    \n",
    "    # This line reads the CSV file specified by 'Wedge_Unzipped\\\\' + uz_file into a DataFrame called big_wedge. The sep \n",
    "    # parameter is set to the delimiter specific to the file (delimiters[uz_file]), and the encoding parameter is set \n",
    "    # to \"utf-8\" to ensure proper character encoding.\n",
    "    \n",
    "    big_wedge = pd.read_csv('Wedge_Unzipped\\\\'+uz_file,sep=delimiters[uz_file], encoding = \"utf-8\") \n",
    "    \n",
    "    # Replaces all \\N and ' ' with gbq ready null values.\n",
    "    \n",
    "    big_wedge = big_wedge.replace(r'\\N', np.nan).replace(r' ', np.nan) \n",
    "    \n",
    "    # This code block iterates over each column in the big_wedge DataFrame using enumerate(). It checks the data type \n",
    "    # of each column and performs type conversions if necessary. If the column's data type is object, it converts the \n",
    "    # column to the str data type using astype() and replaces the string 'nan' with NaN values. If the column's data \n",
    "    # type is \"int64\", it converts the column to the float data type using astype().\n",
    "    \n",
    "    for idx, column in enumerate(big_wedge) :\n",
    "        \n",
    "        # Converts all object columns to strings and replaces 'nan' with gbq ready null values.\n",
    "        \n",
    "        if big_wedge[column].dtypes == object : \n",
    "            big_wedge = big_wedge.astype({column :'str'}).replace('nan', np.nan)\n",
    "            \n",
    "        # Converts all integer columns to floats.  \n",
    "        \n",
    "        if big_wedge[column].dtypes == \"int64\" : \n",
    "            big_wedge = big_wedge.astype({column :'float'})\n",
    "            \n",
    "    # Converts datetime columns to timestamp.  \n",
    "    \n",
    "    big_wedge['datetime'] = pd.to_datetime(big_wedge['datetime']) \n",
    "    \n",
    "    # List of columns to convert to float.\n",
    "    \n",
    "    cols = ['wicable','taxexempt','percentDiscount','receipt','match_id','local','organic','itemstatus','tenderstatus'] \n",
    "    \n",
    "    # Converts cols to float.\n",
    "    \n",
    "    for idx, col in enumerate(cols) :\n",
    "        big_wedge[col] = pd.to_numeric(big_wedge[col])\n",
    "        \n",
    "    # List of columns to convert to boolean. \n",
    "    \n",
    "    cols2 = ['memType','staff','batchHeaderID','display', 'wicable', 'taxexempt', 'local'] \n",
    "    \n",
    "    # Converts 1 and 0 to True and False by mapping, then converts to boolean while preserving null values.\n",
    "    \n",
    "    for idx, col in enumerate(cols2) :\n",
    "        big_wedge[col] = big_wedge[col].map({1:True, 0:False}).astype('boolean') \n",
    "#     break\n",
    "\n",
    "    # Uploading all data files to GBQ.\n",
    "    \n",
    "    # These three lines extract the table name from each file name, construct the table ID \n",
    "    # using the project ID, dataset ID, and table name, and then write the DataFrame (big_wedge) to the specified \n",
    "    # BigQuery table using the pandas_gbq.to_gbq() function.\n",
    "    \n",
    "    # This line splits the uz_file variable at the period (.) and assigns the first part to table_name. The \n",
    "    # underscore _ is used as a placeholder to ignore the second part of the split result.\n",
    "    \n",
    "    table_name, _ = uz_file.split(\".\")\n",
    "    \n",
    "    # This line joins the gbq_proj_id, dataset_id, and table_name together using periods (.) as separators. It \n",
    "    # creates a full table identifier in the format of project_id.dataset_id.table_name. The resulting string is \n",
    "    # assigned to the table_id variable.\n",
    "    \n",
    "    table_id = \".\".join([gbq_proj_id,dataset_id,table_name])\n",
    "    \n",
    "    # This line uses the to_gbq() function from the pandas_gbq module to write the big_wedge DataFrame to the \n",
    "    # specified BigQuery table.\n",
    "    \n",
    "    pandas_gbq.to_gbq(big_wedge, table_id, project_id=gbq_proj_id, if_exists=\"replace\")\n",
    "    \n",
    "    # It takes the following arguments:\n",
    "\n",
    "    # big_wedge: The DataFrame to be written to BigQuery.\n",
    "    # table_id: The fully qualified table identifier in the format of project_id.dataset_id.table_name.\n",
    "    # project_id: The project ID associated with the BigQuery table.\n",
    "    # if_exists=\"replace\": This parameter specifies the behavior if the table already exists. In this case, it is set \n",
    "    # to \"replace\", which means that if the table already exists, it will be replaced with the new data from the DataFrame.\n",
    "    \n",
    "#     break    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
